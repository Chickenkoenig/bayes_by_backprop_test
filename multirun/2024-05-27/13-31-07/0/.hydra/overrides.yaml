- model.architecture.activation=ReLU
- model.architecture.update_interval=5
- model.architecture.max_cols=5
- train.epochs=8000
- train.learning_rate=0.01
- +experiment=large_sin_gap/swag_ensemble_exp
